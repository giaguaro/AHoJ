# -*- coding: utf-8 -*-
"""
Created on Fri May 13 18:33:16 2022

@author: ChrisH
"""

''' test residue mapping'''

import os, pathlib, wget
#import sys
from lxml import etree
#from get_root_path import root_path
'''
import pickle
from dataclasses import dataclass

import __main__
__main__.pymol_argv = ['pymol', '-qc']  # Quiet and no GUI
import pymol.cmd as cmd
'''
'''
def root_path():
    npath = os.path.normpath(os.getcwd())   # Normalize the path string into a proper string for the OS
    if npath.split(os.sep)[1] == 'Users' and 'Chris' in npath.split(os.sep)[2]: # Check "User" and "Chris" are part of the path
        path0 = os.path.join(npath.split(os.sep)[0], '/', npath.split(os.sep)[1], npath.split(os.sep)[2])   
    if os.path.exists(path0):
        memo = "Root path found >> " + path0
    else:
        memo = 'Error finding root path in working dir:' + npath        
    print(memo)
    return path0

@dataclass
class PrecompiledData:
    """
    Pre-compiled data needed for computation
    UniProt PDB mapping
    """
    dict_SIFTS: dict   # regular SIFTS dictionary
    dict_rSIFTS: dict  # reverse SIFTS (SPnum) dictionary


def load_dict_binary(path):
    return pickle.load(open(path, "rb"))
'''

def download_sifts_xml_gz(pdb_id, sifts_dir):
    urlA = 'ftp://ftp.ebi.ac.uk/pub/databases/msd/sifts/split_xml/'
    ext = '.xml.gz'
    middle_bit = pdb_id[1:3]
    pdb_id = pdb_id.lower()
    url = urlA + f'{middle_bit}/' + pdb_id + ext
    subdir = f'{sifts_dir}/{middle_bit}'
    file_path = f'{subdir}/{pdb_id}{ext}'
    if not os.path.isfile(file_path):
        pathlib.Path(subdir).mkdir(exist_ok=True)
        print(f'Downloading: {pdb_id + ext}')
        wget.download(url, subdir)
        return file_path
    else:
        return file_path


def download_mmCIF_gz2(pdb_id, pdb_dir):   # Version 2 of download mmCIF gz (without exception handling)
    # in pdb_dir mimic directory structure of FTP/rsynced whole PDB
    # e.g.: 4ZZW is in {pdb_dir}/zz/4zzw.cif.gz

    urlA = 'https://files.rcsb.org/download/'
    ext = '.cif.gz'
    url = urlA + pdb_id.upper() + ext
    pdb_id = pdb_id.lower()
    middle_bit = pdb_id[1:3]
    subdir = f'{pdb_dir}/{middle_bit}'
    file_path = f'{subdir}/{pdb_id}{ext}'

    if not os.path.isfile(file_path):
        pathlib.Path(subdir).mkdir(exist_ok=True)
        print(f'Downloading: {pdb_id + ext}')
        wget.download(url, subdir)
        return file_path
    else:
        return file_path

'''
def load_precompiled_data_bin(workdir) -> PrecompiledData:
    pathSIFTS = workdir + '/SIFTS'
    fileSIFTSdict = pathSIFTS + '/pdb_chain_uniprot_dict.bin'
    fileRSIFTS = pathSIFTS + '/pdb_chain_uniprot_REVERSE_SPnum.bin'

    print('Loading SIFTS dictionary')
    dict_SIFTS = load_dict_binary(fileSIFTSdict)

    print('Loading reverse SIFTS dictionary')
    dict_rSIFTS = load_dict_binary(fileRSIFTS)

    return PrecompiledData(dict_SIFTS=dict_SIFTS, dict_rSIFTS=dict_rSIFTS)


def load_precompiled_data(workdir) -> PrecompiledData:
    """Load pre-compiled data generated by prepare.py"""
    res = load_precompiled_data_bin(workdir)
    print('Done loading pre-compiled data\n')
    return res
'''

def print_dict_readable(input_dict, header_msg):
    print('')
    print(header_msg)
    for i, j in input_dict.items():
        print(i, j)


def map_uniprot_resnum_to_pdb2(uniprot_resnum_list, sifts_xml_file):

    # Load the xml with lxml
    parser = etree.XMLParser(ns_clean=True)
    tree = etree.parse(sifts_xml_file, parser)
    root = tree.getroot()
    my_pdb_resnum = None
    # TODO: "Engineered_Mutation is also a possible annotation, need to figure out what to do with that
    my_pdb_annotation = False

    # Parse list of residues and their chains
    list_out = list()            
    for resichain in uniprot_resnum_list:
        resichain.replace('_', '.')
        chain_id = resichain.split('.')[0]
        uniprot_resnum = resichain.split('.')[1]
        print(chain_id, uniprot_resnum)

        # Find the right chain (entities in the xml doc)
        ent = './/{http://www.ebi.ac.uk/pdbe/docs/sifts/eFamily.xsd}entity'
        for chain in root.findall(ent):
            # IMPORTANT - entityId is not the chain ID
            if chain.attrib['entityId'] == chain_id:
                # Find the "crossRefDb" tag that has the attributes dbSource="UniProt" and  dbResNum="your_resnum_here"
                # Then match it to the crossRefDb dbResNum that has the attribute dbSource="PDBresnum"

                # Check if uniprot + resnum even exists in the sifts file (it won't if the pdb doesn't contain the residue)
                ures = './/{http://www.ebi.ac.uk/pdbe/docs/sifts/eFamily.xsd}crossRefDb[@dbSource="UniProt"][@dbResNum="%s"]' % uniprot_resnum
                my_uniprot_residue = chain.findall(ures)

                if len(my_uniprot_residue) == 1: # this is prolly a list and we need it to have 1 element
                    # Get crossRefDb dbSource="PDB"
                    parent = my_uniprot_residue[0].getparent()
                    pres = './/{http://www.ebi.ac.uk/pdbe/docs/sifts/eFamily.xsd}crossRefDb[@dbSource="PDB"]'
                    my_pdb_residue = parent.findall(pres)
                    my_pdb_resnum = int(my_pdb_residue[0].attrib['dbResNum'])
                    my_pdb_chain = str(my_pdb_residue[0].attrib['dbChainId'])
                    resichain_pdb = my_pdb_chain + '.' + str(my_pdb_resnum)

                    # Get <residueDetail dbSource="PDBe" property="Annotation">
                    # Will be Not_Observed if it is not seen in the PDB
                    anno = './/{http://www.ebi.ac.uk/pdbe/docs/sifts/eFamily.xsd}residueDetail[@dbSource="PDBe"][@property="Annotation"]'
                    my_pdb_annotation = parent.findall(anno)
                    if len(my_pdb_annotation) == 1:
                        my_pdb_annotation = my_pdb_annotation[0].text
                        if my_pdb_annotation == 'Not_Observed':
                            my_pdb_annotation = False
                            list_out.append(resichain + '>*' + resichain_pdb)
                    else:
                        my_pdb_annotation = True
                        list_out.append(resichain + '>' + resichain_pdb)
                else:
                    list_out.append(resichain + '>None')#  + None)
    return list_out


def map_pdb_resnum_to_uniprot(pdb_resnum_list, sifts_xml_file):

    # Load the xml with lxml
    parser = etree.XMLParser(ns_clean=True)
    tree = etree.parse(sifts_xml_file, parser)
    root = tree.getroot()
    my_unp_resnum = None
    # TODO: "Engineered_Mutation is also a possible annotation, need to figure out what to do with that
    my_pdb_annotation = False

    # Parse list of residues and their chains
    list_out = list()            
    for resichain in pdb_resnum_list:
        segi_id = resichain.split('_')[0]
        chain_id = resichain.split('_')[1]
        pdb_resnum = resichain.split('_')[3]
        resichain_frmt = '.'.join([segi_id, chain_id, pdb_resnum]) # Reformat the string to more compact form
        #print(segi_id, chain_id, pdb_resnum)

        # Find the right segment (entities in the xml doc)
        ent = './/{http://www.ebi.ac.uk/pdbe/docs/sifts/eFamily.xsd}entity'
        for segment in root.findall(ent):
            # IMPORTANT - entityId is not the chain ID
            if segment.attrib['entityId'] == segi_id:
                # Find the "crossRefDb" tag that has the attributes dbSource="UniProt" and  dbResNum="your_resnum_here"
                # Then match it to the crossRefDb dbResNum that has the attribute dbSource="PDBresnum"

                # Check if uniprot + resnum even exists in the sifts file (it won't if the pdb doesn't contain the residue)
                ures = './/{http://www.ebi.ac.uk/pdbe/docs/sifts/eFamily.xsd}crossRefDb[@dbSource="PDB"][@dbResNum="%s"]' % pdb_resnum
                my_pdb_residue = segment.findall(ures)

                if len(my_pdb_residue) == 1: # this is prolly a list and we need it to have 1 element
                    # Get crossRefDb dbSource="PDB"
                    parent = my_pdb_residue[0].getparent()
                    pres = './/{http://www.ebi.ac.uk/pdbe/docs/sifts/eFamily.xsd}crossRefDb[@dbSource="UniProt"]'
                    my_uniprot_residue = parent.findall(pres)
                    my_unp_resnum = int(my_uniprot_residue[0].attrib['dbResNum'])
                    #my_pdb_chain = str(my_uniprot_residue[0].attrib['dbChainId']) # UniProt field has no chain in xml
                    my_pdb_chain = chain_id
                    resichain_pdb = my_pdb_chain + '.' + str(my_unp_resnum)

                    # Get <residueDetail dbSource="PDBe" property="Annotation">
                    # Will be Not_Observed if it is not seen in the PDB
                    anno = './/{http://www.ebi.ac.uk/pdbe/docs/sifts/eFamily.xsd}residueDetail[@dbSource="PDBe"][@property="Annotation"]'
                    my_pdb_annotation = parent.findall(anno)
                    if len(my_pdb_annotation) == 1:
                        my_pdb_annotation = my_pdb_annotation[0].text
                        if my_pdb_annotation == 'Not_Observed':
                            my_pdb_annotation = False
                            list_out.append(resichain_frmt + '>*' + resichain_pdb) # Not observed in structure
                    else:
                        my_pdb_annotation = True
                        list_out.append(resichain_frmt + '>' + resichain_pdb)
                else:
                    list_out.append(resichain_frmt + '>None')#  + None)
    return list_out


'''
# Directories
path0 = root_path()    
path_xml = path0 +  '/Documents/Bioinfo_local/webserver/rsd_mappings'
path_structures = path0 +  '/Documents/Bioinfo_local/webserver/structures'
workdir = path0 + '/Documents/Bioinfo_local/webserver'

# Load SIFTS local files
data = load_precompiled_data(workdir)
dict_SIFTS = data.dict_SIFTS
dict_rSIFTS = data.dict_rSIFTS

# Define list of residues and their chains
#resi_list = ['L.25', 'P.1', 'A.26', 'B.516', 'A.517', 'A.518']
#resi_dict = {'903_L_HG': ['B_L_CYS_1018', 'B_L_SER_1019', 'B_L_CYS_1130'], '907_P_HG': ['A_P_MET_313', 'A_P_TYR_317']}


# Define structure
struct = '1aro'
pdb_file = download_mmCIF_gz2(struct, path_structures)

# Define ligands
ligs = ['903_L_HG', '907_P_HG', '909_P_HG', '905_P_HG']
lig_scan_radius = '4'


# Start PyMOL session

cmd.reinitialize('everything')
cmd.load(pdb_file)

# Find binding residues of ligand(s) in structure
binding_res_dict = dict()

for ligand in ligs:
    resi = ligand.split('_')[0]
    chain = ligand.split('_')[1]
    resn = ligand.split('_')[2]

    # Find ligand
    cmd.select(ligand + '_' + struct, struct + ' and chain ' + chain + ' and resi ' + resi + ' and resn ' + resn)

    # Find & select binding residues
    s1 = struct + ' and polymer'
    s2 = ligand + '_' + struct
    cmd.select('arnd_' + ligand, s1 + ' near_to ' + lig_scan_radius + ' of ' + s2)

    # Iterate and identify residues
    myspace_positions = {'binding_resis': []}
    cmd.iterate('arnd_' + ligand, 'binding_resis.append( segi+"_"+chain+"_"+resn+"_"+resi )', space=myspace_positions)

    # Remove duplicate values from query_lig_positions & Transfer binding sites to global dictionary
    for key, value in myspace_positions.items():
        binding_res_dict[ligand] = list(myspace_positions.fromkeys(value))


binding_res_unpacked = []
for sublist in binding_res_dict.values():
    binding_res_unpacked.extend(sublist)
binding_res_unpacked = list(dict.fromkeys(binding_res_unpacked)) # Remove duplicates

total1 = sum(len(v) for v in binding_res_dict.values())
total2 = len(binding_res_unpacked)
#print(binding_res_dict)
print(f'Parsing query structure [{struct}]')
print('\nDetecting binding residues of query chain (segment, chain, pdb residue number)')
print(f'\nBinding residues clustered per binding site:\n{binding_res_dict}')
print(f'\nUnique binding residues (segment, chain, pdb residue number):\n{binding_res_unpacked}')
print(f'\nChecking for duplicate binding residues (total/unique): [{total1}]/[{total2}]')
if total1 == total2:
    print('No duplicate binding residues in query structure (chain)')
else:
    print('Dupicate binding residues detected')

#sys.exit(0)


#### Residue mapping section

# Download xml

#struct = '1lba'
try:
    pdb_xml = download_sifts_xml_gz(struct, path_xml)
except Exception:
    print('SIFTS server unavailable')
    sys.exit(0)

# Map PDB (binding) residues of query to UniProt residue numbers
print('\nMapping query chain binding residues from PDB to UniProt numbering')
bndgres_pdb_to_unp =  map_pdb_resnum_to_uniprot(binding_res_unpacked, pdb_xml)
print(bndgres_pdb_to_unp)

# Check if these UniProt residues are present (observed) in candidate structure

user_structchains = ['1aroL', '1aroP']
overlap_threshold = 0

user_structchains_unp = dict()

for user_structchain in user_structchains:
    try:
        usr_uniprot_id = dict_SIFTS[user_structchain]
        #print(user_structchain, usr_uniprot_id)
        user_structchains_unp[user_structchain] = usr_uniprot_id 
    except:
        #user_structchains.remove(user_structchain)
        #discarded_chains.append(user_structchain + '\t' + 'Query chain not assigned UniProt ID\n')
        #usr_structchains_unverified.append(user_structchain)
        print('chain not found')
print(f'\nUniProt IDs for query chains:\n{user_structchains_unp}')

# Get apo candidates from rSIFTS dict, with their UniProt range(s)
candidates_unp_dict = dict()
for key, value in user_structchains_unp.items():
    candidates = dict_rSIFTS[value]
    candidates_unp_dict[key] = candidates
'''
'''print('\ncandidates_unp_dict')
print_dict_readable(candidates_unp_dict)'''

# Group (UNP num) binding residues by chain (list in, dict out)
def group_mapped_res_by_chain(mapped_res_list):
    bndgres_pdb_to_unp_chains = dict()
    for unp_binding_res in mapped_res_list:
        unp_part = unp_binding_res.split('>')[1]
        chain = unp_part.split('.')[0]
        unpnum = unp_part.split('.')[1]
        bndgres_pdb_to_unp_chains.setdefault(chain, []).append(unpnum)
    return bndgres_pdb_to_unp_chains

'''bndgres_pdb_to_unp_chains = group_mapped_res_by_chain(bndgres_pdb_to_unp)
'''
# Add fake binding residues for testing
#fake_pos = ['1', '2', '6', '7', '8', '20', '40', '150', '151', '152', '9000']
#bndgres_pdb_to_unp_chains['L'] = fake_pos
#bndgres_pdb_to_unp_chains['P'] = fake_pos

'''print(f'\nBinding residues [UNP] grouped by query structure chain:\n{bndgres_pdb_to_unp_chains}')
'''




# Find whether mapped binding residues are present in each candidate chain
def examine_cndt_mapped_bs_res(dict_of_bndgres_pdb_to_unp, query_struct, candidates_unp_dict):
    candidate_hits = dict()
    for chain, positions in dict_of_bndgres_pdb_to_unp.items():
        chain = chain # to use existing candidates dict
        query_structchain = query_struct + chain
        candidates = candidates_unp_dict[query_structchain] # Get candidates from UniProt ID
        
        for candidate_entry in candidates:
            candidate_structchain = candidate_entry.split()[0]
            candidate_struct = candidate_structchain[:4]
            
            if candidate_struct != query_struct: # eliminate candidates of the same structure
                
                # Make dict with candidate structchain and UniProt range(s) as values, then check overlap
                cndt_SP_BEG = int(candidate_entry.split()[1])
                cndt_SP_END = int(candidate_entry.split()[2])
                
                # Loop through positions, look if position is within UniProt range
                for position in positions:
                    if int(position) >= cndt_SP_BEG and int(position) <= cndt_SP_END:
                        candidate_hits.setdefault(candidate_structchain+'.'+query_structchain, []).append(chain + '.' + position + ' ' + str(1))
                    else:
                        candidate_hits.setdefault(candidate_structchain+'.'+query_structchain, []).append(chain + '.' + position + ' ' + str(0))
    return candidate_hits


'''candidate_hits = examine_cndt_mapped_bs_res(bndgres_pdb_to_unp_chains) 
'''#print_dict_readable(candidate_hits)

# Intermediate step to remove negative score when positive is present for the same position
def remove_negative_duplicate_cndt_bs_res_pos(dict_of_candidate_bs_rsds_assessment):
    candidate_metahits = dict()
    for candidate, scores in dict_of_candidate_bs_rsds_assessment.items():
        score_list = list()
        for score in scores:
            position = score.split()[0]
            result = score.split()[1]
            bad_result = position + ' ' + '0'
            good_result = position + ' ' + '1'
            if bad_result in score_list and result == '1':
                score_list.remove(bad_result)
                score_list.append(position + ' ' + result)
            elif good_result in score_list and result == '0':
                pass
            else:
                score_list.append(position + ' ' + result)
        candidate_metahits[candidate] = score_list
    return candidate_metahits

'''candidate_metahits = remove_negative_duplicate_cndt_bs_res_pos(candidate_hits)
#print_dict_readable(candidate_metahits)'''

# Count how many binding residues (out of total) are present in candidate
def evaluate_candidate_bs_rsds(dict_of_candidate_bs_rsds_scores):
    # dict e.g. "1lbaA.1aroL ['L.19 1', 'L.20 1', 'L.131 1']"    
    candidate_scores = dict()
    for candidate, scores in dict_of_candidate_bs_rsds_scores.items():
        current_score = 0  # reset
        for score in scores:
            #position = score.split()[0]
            result = score.split()[1]
            if result == '1':
                current_score += 1
        ratio = 100 * current_score / len(scores)
        ratio = str(round(ratio)) + '%'
        candidate_scores.setdefault(candidate, []).append(str(current_score) + '/' + str(len(scores)) + ' ' + ratio)
    return candidate_scores


# Put candidates over certain threshold to dict for further processing (applies on precalculated % scores)
def good_candidates_from_residue_mapping(candidate_score_dict, binding_residue_threshold):
    dict_rsd_map_candidates = dict()
    for key, value in candidate_score_dict.items():
        cndt_structchain_part = key.split('.')[0]
        qr_structchain_part = key.split('.')[1]
        brsds_percent = int(value[0].split()[1][:-1])
        if brsds_percent >= binding_residue_threshold:
            #print(cndt_structchain_part, brsds_percent)
            dict_rsd_map_candidates.setdefault(qr_structchain_part, []).append(cndt_structchain_part)
    return dict_rsd_map_candidates

# Put candidates under certain threshold to dict for further processing (applies on precalculated % scores)
def bad_candidates_from_residue_mapping(candidate_score_dict, binding_residue_threshold):
    bad_candidates = dict()
    for key, value in candidate_score_dict.items():
        cndt_structchain_part = key.split('.')[0]
        qr_structchain_part = key.split('.')[1]
        brsds_percent = int(value[0].split()[1][:-1])
        if brsds_percent < binding_residue_threshold:
            #print(cndt_structchain_part, brsds_percent)
            bad_candidates.setdefault(qr_structchain_part, []).append(cndt_structchain_part)
    return bad_candidates

